{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 🧠 Pretraining & Fine-Tuning in LLMs\n",
    "\n",
    "## 🎯 Intent\n",
    "\n",
    "Train large models 📚 on massive text, then adapt them for specific tasks.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔑 Steps\n",
    "\n",
    "* 📖 **Pretraining** → learn general language patterns from huge corpora (Wikipedia, books, code).\n",
    "* 🎯 **Fine-Tuning** → adapt to a task (sentiment, QA, summarization).\n",
    "* 🔄 **Transfer Learning** → reuse knowledge instead of training from scratch.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Quick Summary\n",
    "\n",
    "* 👉 Pretraining = general knowledge 🌍.\n",
    "* 👉 Fine-tuning = specialize for a job 🎯.\n",
    "* 👉 Saves time, cost & compute.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
