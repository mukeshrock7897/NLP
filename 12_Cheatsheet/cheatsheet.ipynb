{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 📚 NLP Interview Preparation Cheatsheet\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣ NLP Core Pipeline 🛠️\n",
    "\n",
    "| 🔑 Step                   | 📌 What it’s for                      | 🐍 Python Imports & Functions                                                | 📝 Notes                                          |\n",
    "| ------------------------- | ------------------------------------- | ---------------------------------------------------------------------------- | ------------------------------------------------- |\n",
    "| Data Collection 🌐        | Gather raw data from APIs, web, files | `requests`, `beautifulsoup4`, `pandas`                                       | APIs, scraping, open datasets                     |\n",
    "| Preprocessing 🧹          | Clean & normalize text                | `re`, `nltk.corpus.stopwords`, `string`                                      | Lowercasing, stopwords, punctuation removal       |\n",
    "| Tokenization ✂️           | Break text into words/subwords        | `nltk.word_tokenize`, `spacy.load().tokenizer`, `transformers.AutoTokenizer` | Rule-based vs subword BPE                         |\n",
    "| Feature Representation 🧩 | Convert text → vectors                | `sklearn.feature_extraction.text.CountVectorizer`, `TfidfVectorizer`         | Bag-of-Words, TF-IDF, Embeddings                  |\n",
    "| Modeling 🤖               | Build ML/DL models                    | `scikit-learn`, `torch`, `tensorflow`, `transformers`                        | Classical (NB, SVM) + DL (RNN, LSTM, Transformer) |\n",
    "| Evaluation 📊             | Measure performance                   | `sklearn.metrics` (`accuracy_score`, `f1_score`)                             | Also BLEU, ROUGE for seq2seq                      |\n",
    "| Deployment 🚀             | Serve models                          | `flask`, `fastapi`, `bentoml`, `torchserve`                                  | REST APIs, cloud                                  |\n",
    "| Monitoring 🔍             | Track drift, errors                   | `prometheus`, `mlflow`, `evidently`                                          | Essential for production                          |\n",
    "\n",
    "---\n",
    "\n",
    "## 2️⃣ Fundamentals of Linguistics 🌍\n",
    "\n",
    "| 🧩 Topic         | 📌 Use in NLP                   | 🐍 Example / Notes                  |\n",
    "| ---------------- | ------------------------------- | ----------------------------------- |\n",
    "| Morphology 🧬    | Word formation (stems, affixes) | Stemming vs Lemmatization           |\n",
    "| Syntax 🌳        | Sentence structure              | Dependency parsing, POS tagging     |\n",
    "| Semantics 💡     | Meaning representation          | Word Sense Disambiguation           |\n",
    "| Pragmatics 🗣️   | Contextual meaning              | Coreference resolution              |\n",
    "| Ethics & Bias ⚖️ | Data fairness, inclusivity      | Avoid bias in embeddings & datasets |\n",
    "\n",
    "---\n",
    "\n",
    "## 3️⃣ Programming Tools ⚙️\n",
    "\n",
    "| 🛠️ Category                | 📌 Purpose        | 🐍 Imports / Tools                               |\n",
    "| --------------------------- | ----------------- | ------------------------------------------------ |\n",
    "| Python Essentials 🐍        | Basic text ops    | `str.split()`, `re.sub()`, `collections.Counter` |\n",
    "| NLP Libraries 📚            | Ready pipelines   | `nltk`, `spacy`, `gensim`                        |\n",
    "| Deep Learning Frameworks 🔥 | Training models   | `torch`, `tensorflow.keras`                      |\n",
    "| Industry Tools 🏭           | Deployment & eval | `transformers`, `langchain`, `mlflow`            |\n",
    "\n",
    "---\n",
    "\n",
    "## 4️⃣ Classical ML in NLP 🧮\n",
    "\n",
    "| 📌 Algorithm          | 🐍 Import / Function                                  | 🔎 Notes                      |\n",
    "| --------------------- | ----------------------------------------------------- | ----------------------------- |\n",
    "| Naive Bayes 📊        | `from sklearn.naive_bayes import MultinomialNB`       | Great for text classification |\n",
    "| Logistic Regression ➗ | `from sklearn.linear_model import LogisticRegression` | Baseline classifier           |\n",
    "| SVM ⚔️                | `from sklearn.svm import SVC`                         | Good for high-dim text        |\n",
    "| CRF 📋                | `sklearn-crfsuite`                                    | Sequence labeling (NER, POS)  |\n",
    "\n",
    "---\n",
    "\n",
    "## 5️⃣ Deep Learning in NLP 🔥\n",
    "\n",
    "| 🧠 Model Type   | 🐍 Imports                                       | 📝 Notes                                        |\n",
    "| --------------- | ------------------------------------------------ | ----------------------------------------------- |\n",
    "| RNNs 🔄         | `torch.nn.RNN`, `keras.layers.SimpleRNN`         | Handle sequences but suffer vanishing gradients |\n",
    "| LSTMs ⏳         | `torch.nn.LSTM`, `keras.layers.LSTM`             | Capture long-term dependencies                  |\n",
    "| GRUs ⚡          | `torch.nn.GRU`                                   | Lighter than LSTM                               |\n",
    "| CNNs for NLP 🌀 | `keras.layers.Conv1D`                            | Text classification, sentence encoding          |\n",
    "| Attention ✨     | `torch.nn.MultiheadAttention`                    | Focus on important tokens                       |\n",
    "| Seq2Seq 🔁      | `torch.nn.Transformer`, `keras.layers.Attention` | Translation, summarization                      |\n",
    "\n",
    "---\n",
    "\n",
    "## 6️⃣ Transformers & LLMs ⚡\n",
    "\n",
    "| 📌 Concept                    | 🐍 Imports                                  | 🔎 Notes                                            |\n",
    "| ----------------------------- | ------------------------------------------- | --------------------------------------------------- |\n",
    "| Self-Attention 👀             | `torch.nn.MultiheadAttention`               | Core of Transformers                                |\n",
    "| Transformer Architectures 🏗️ | `transformers.BertModel`, `GPT2LMHeadModel` | BERT (encoder), GPT (decoder), T5 (encoder-decoder) |\n",
    "| Fine-Tuning 🔧                | `Trainer` API in `transformers`             | Domain-specific adaptation                          |\n",
    "| Prompt Engineering 📝         | `pipeline(\"text-generation\")`               | Few-shot, zero-shot                                 |\n",
    "| Applications 💡               | QA, Summarization, Chatbots, RAG            | Hugging Face Pipelines                              |\n",
    "\n",
    "---\n",
    "\n",
    "## 7️⃣ Core NLP Tasks 📝\n",
    "\n",
    "| 🎯 Task                   | 🐍 Tools / Imports                                              | 📝 Notes                        |\n",
    "| ------------------------- | --------------------------------------------------------------- | ------------------------------- |\n",
    "| Text Classification 🏷️   | `LogisticRegression`, `BERT`, `pipeline(\"text-classification\")` | Sentiment, topic classification |\n",
    "| Information Extraction 📑 | `spacy.ner`, `transformers` NER models                          | NER, Relation Extraction        |\n",
    "| Text Generation ✍️        | `GPT2LMHeadModel`, `pipeline(\"text-generation\")`                | Dialogue, story generation      |\n",
    "| Summarization 📚          | `pipeline(\"summarization\")`                                     | Abstractive vs Extractive       |\n",
    "| Machine Translation 🌐    | `MarianMTModel`, `pipeline(\"translation\")`                      | Hugging Face pretrained models  |\n",
    "\n",
    "---\n",
    "\n",
    "## 8️⃣ Evaluation Metrics 📊\n",
    "\n",
    "| 📏 Metric     | 📌 What it measures          | 🐍 Function                      |\n",
    "| ------------- | ---------------------------- | -------------------------------- |\n",
    "| Accuracy ✔️   | Correct predictions / total  | `accuracy_score(y_true, y_pred)` |\n",
    "| Precision 🎯  | Correct positive predictions | `precision_score()`              |\n",
    "| Recall 🔎     | % of positives captured      | `recall_score()`                 |\n",
    "| F1-Score ⚖️   | Harmonic mean of P & R       | `f1_score()`                     |\n",
    "| BLEU 🌍       | MT quality (n-gram overlap)  | `nltk.translate.bleu_score`      |\n",
    "| ROUGE 📖      | Summarization quality        | `rouge_score`                    |\n",
    "| Perplexity 🤯 | Language model fluency       | Lower is better                  |\n",
    "\n",
    "---\n",
    "\n",
    "## 9️⃣ Advanced Topics 🚀\n",
    "\n",
    "| 🧩 Topic                                | 📌 Why important            | 📝 Notes                          |\n",
    "| --------------------------------------- | --------------------------- | --------------------------------- |\n",
    "| Transfer Learning 🔄                    | Adapt pretrained models     | Saves data + compute              |\n",
    "| Multilingual NLP 🌍                     | XLM-R, mBERT                | Cross-lingual tasks               |\n",
    "| Explainability 🧐                       | SHAP, LIME                  | Model interpretability            |\n",
    "| RAG (Retrieval-Augmented Generation) 🔍 | Combine search + generation | For enterprise QA                 |\n",
    "| Agentic AI 🤖                           | Tools + reasoning           | LangChain Agents                  |\n",
    "| Ethics & Safety ⚖️                      | Avoid harmful outputs       | Bias mitigation, toxicity filters |\n",
    "\n",
    "---\n",
    "\n",
    "## 🔟 Python Snippets & Built-ins 🐍\n",
    "\n",
    "| Function              | Example                   | Use                  |\n",
    "| --------------------- | ------------------------- | -------------------- |\n",
    "| `str.lower()`         | `\"Hello\".lower()`         | Normalize case       |\n",
    "| `re.sub()`            | `re.sub(r\"\\d\", \"\", text)` | Remove digits        |\n",
    "| `split()`             | `\"I love NLP\".split()`    | Tokenization (basic) |\n",
    "| `collections.Counter` | `Counter(words)`          | Word frequency       |\n",
    "| `zip()`               | `zip(words, tags)`        | Pair tokens with POS |\n",
    "| `enumerate()`         | Iterate with index        | Helpful in loops     |\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
